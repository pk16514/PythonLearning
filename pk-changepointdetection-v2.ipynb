{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-20T17:45:02.447317Z","iopub.execute_input":"2022-07-20T17:45:02.447775Z","iopub.status.idle":"2022-07-20T17:45:02.493577Z","shell.execute_reply.started":"2022-07-20T17:45:02.447675Z","shell.execute_reply":"2022-07-20T17:45:02.492815Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom scipy import spatial\nfrom sklearn.cluster import DBSCAN\n\n!pip install changefinder\nimport changefinder\n\n!pip install lasio\nimport lasio\nimport glob\nimport os\nimport cv2\nimport re\nfrom PIL import Image\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:45:02.496712Z","iopub.execute_input":"2022-07-20T17:45:02.498328Z","iopub.status.idle":"2022-07-20T17:45:32.691041Z","shell.execute_reply.started":"2022-07-20T17:45:02.498271Z","shell.execute_reply":"2022-07-20T17:45:32.689970Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"directory = \"Features_directory\" \nparent_dir = \"./\"\npath = os.path.join(parent_dir, directory) \nos.makedirs(path, exist_ok=True) \nprint(\"Directory '% s' created\" % directory) \n\ndirectory = \"Well_markers_pics\" \nparent_dir = \"./\"\npath = os.path.join(parent_dir, directory) \nos.makedirs(path, exist_ok=True) \nprint(\"Directory '% s' created\" % directory) \n\ndirectory = \"Well_desc\" \nparent_dir = \"./\"\npath = os.path.join(parent_dir, directory) \nos.makedirs(path, exist_ok=True) \nprint(\"Directory '% s' created\" % directory)\n\ndirectory = \"Image_directory\"\nparent_dir = \"./\"\npath = os.path.join(parent_dir, directory) \nos.makedirs(path, exist_ok=True) \nprint(\"Directory '% s' created\" % directory)\n\ndirectory = \"Org_DataFrame\"\nparent_dir = \"./\"\npath = os.path.join(parent_dir, directory) \nos.makedirs(path, exist_ok=True) \nprint(\"Directory '% s' created\" % directory)\n\ndirectory = \"WellImages_array_directory\"\nparent_dir = \"./\"\npath = os.path.join(parent_dir, directory) \nos.makedirs(path, exist_ok=True) \nprint(\"Directory '% s' created\" % directory)\n\ndirectory = \"WellImages_VGGFeatureVector_directory\"\nparent_dir = \"./\"\npath = os.path.join(parent_dir, directory) \nos.makedirs(path, exist_ok=True) \nprint(\"Directory '% s' created\" % directory)\n\ndirectory = \"WellImages_EGSFeatureVector_directory\"\nparent_dir = \"./\"\npath = os.path.join(parent_dir, directory) \nos.makedirs(path, exist_ok=True) \nprint(\"Directory '% s' created\" % directory)\n\ndirectory = \"WellImages_AutoEncoderFeatureVector_directory\"\nparent_dir = \"./\"\npath = os.path.join(parent_dir, directory) \nos.makedirs(path, exist_ok=True) \nprint(\"Directory '% s' created\" % directory)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:45:32.692907Z","iopub.execute_input":"2022-07-20T17:45:32.693282Z","iopub.status.idle":"2022-07-20T17:45:32.713639Z","shell.execute_reply.started":"2022-07-20T17:45:32.693246Z","shell.execute_reply":"2022-07-20T17:45:32.712595Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# import os\n# os.remove(\"./FeatureVector_Matching_168_192.png\")\n# os.remove(\"./Descriptor_Matching_168_192.png\")\n# os.remove(\"./168_192_descriptor_correlation_output.csv\")\n# os.remove(\"./168_192_FeatureVector_correlation_output.csv\")\n# shutil.rmtree(\"./Well_markers_pics\")\n# shutil.rmtree(\"./Image_directory\")\n# shutil.rmtree(\"./Features_directory\")\n# shutil.rmtree(\"./Well_desc\")\n# shutil.rmtree(\"./WellImages_array_directory\")\n# shutil.rmtree(\"./WellImages_FeatureVector_directory\")\n# shutil.rmtree(\"./Org_DataFrame\")","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:45:32.715132Z","iopub.execute_input":"2022-07-20T17:45:32.716139Z","iopub.status.idle":"2022-07-20T17:45:32.724624Z","shell.execute_reply.started":"2022-07-20T17:45:32.716087Z","shell.execute_reply":"2022-07-20T17:45:32.723746Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def findChangePoints(ts, r, order, smooth):\n    '''\n       r: Discounting rate\n       order: AR model order\n       smooth: smoothing window size T\n    '''\n    cf = changefinder.ChangeFinder(r=r, order=order, smooth=smooth)\n    ts_score = [cf.update(p) for p in ts]\n#     plt.figure(figsize=(30,4))\n#     plt.plot(ts)\n#     plt.figure(figsize=(30,4))\n#     plt.plot(ts_score, color='red')\n    return(ts_score)\n\n\ndef plot_change_points(ts,ts_change_loc):\n    plt.figure(figsize=(30,4))\n    plt.plot(ts)\n    for x in ts_change_loc:\n        plt.axvline(x,lw=2, color='red')\n        \n        \ndef get_change_points(var,r,order,smooth,n_largest):\n    ts_score1 = findChangePoints(var, r = r, order = order, smooth = smooth)\n    ts_change_loc1 = pd.Series(ts_score1).nlargest(n_largest)\n    ts_change_loc1 = ts_change_loc1.index\n#     plot_change_points(var,ts_change_loc1)\n    return ts_change_loc1","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:45:32.726841Z","iopub.execute_input":"2022-07-20T17:45:32.727314Z","iopub.status.idle":"2022-07-20T17:45:32.742521Z","shell.execute_reply.started":"2022-07-20T17:45:32.727254Z","shell.execute_reply":"2022-07-20T17:45:32.741461Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import NearestNeighbors\n\ndef detect_and_compute(lasfile,features):\n    \n    df=lasio.read(lasfile)\n    well_name=df.well.WELL.value\n    df=df.df()\n    df=df.reset_index()\n    df=df[[\"DEPTH\"]+features]\n    df=df.dropna()\n    \n    for i in range(len(features)):\n        df=df[df[features[i]]>=0]\n    df=df.reset_index(drop=True)\n    \n    directory = \"Image_directory/\" + well_name\n    parent_dir = \"./\"\n    path = os.path.join(parent_dir, directory) \n    os.makedirs(path, exist_ok=True)\n    \n    lst=[]\n    for i in features:\n        idx=get_change_points(var=df[i],r=0.1,order=1,smooth=5,n_largest=40).tolist()\n        lst=lst+idx\n        \n    model=DBSCAN(eps=32,min_samples=1)\n    model.fit((np.array(lst)).reshape(len(lst),1))\n    labels=model.labels_\n    unq_labels=np.unique(labels).tolist()\n    labels_lst=labels.tolist()\n    \n    depth_change_points=[]\n    for i in range(len(unq_labels)):\n        depth_change_points.append(np.mean(df[\"DEPTH\"].values[np.array(lst)[np.where(labels ==unq_labels[i])[0][:].tolist()].tolist()]))\n        \n    depth_change_points_array=np.around(np.array(depth_change_points), decimals=2)\n    depth_change_points_array=np.sort(depth_change_points_array)\n    depth_change_points_array=np.delete(depth_change_points_array,[0,-1])\n    \n    idx_lst=[]\n    dept_org=[]\n    nbrs = NearestNeighbors()\n    for i in range(len(depth_change_points_array)):\n        temp= np.array(list(df['DEPTH'])).reshape(-1, 1)\n        nbrs.fit(temp)\n        distance, index = nbrs.kneighbors(np.array([[depth_change_points_array[i]]]))\n        lst = distance.tolist()[0]\n        lst_ = index.tolist()[0]\n        dist = lst[0]\n        idx = lst_[0]\n        idx_lst.append(idx)\n        dept_org.append(df[\"DEPTH\"][idx])\n        \n#         distance,index = spatial.KDTree(df[[\"DEPTH\"]]).query(depth_change_points_array[i])\n#         idx_lst.append(index)\n#         dept_org.append(df[\"DEPTH\"][index])\n    \n    feature_scaled_lst=[]\n    for i in range(len(features)):\n        df[features[i]+\"_scaled\"]=(((df[features[i]]-min(df[features[i]]))/(max(df[features[i]])-min(df[features[i]])))*50)+(i*100)\n        feature_scaled_lst.append(features[i]+\"_scaled\")\n        \n    feature_df=pd.DataFrame()\n    feature_df[\"DEPTH\"]=depth_change_points_array\n    feature_df[\"dept_idx\"]=idx_lst\n    desc_lst=[]\n    image_list = []\n    for i in range(len(feature_df)):\n        image_df = pd.DataFrame()\n        lst=[]\n        k=0\n        for j in feature_scaled_lst:\n            lst=lst + (df[j][feature_df[\"dept_idx\"][i]-32:feature_df[\"dept_idx\"][i]+32]-(k*100)).values.tolist()\n            image_df[j] = (df[j][feature_df[\"dept_idx\"][i]-32:feature_df[\"dept_idx\"][i]+32]-(k*100)).values.tolist()\n            k=k+1\n        \n        scaler = MinMaxScaler(feature_range=(0,255))\n        scaled_keypoints_array = scaler.fit_transform(image_df)\n        scaled_image_df = pd.DataFrame(scaled_keypoints_array, columns=feature_scaled_lst).astype('int')\n        scaled_df_to_array = scaled_image_df.to_numpy().astype(np.uint8)\n        # print(scaled_df_to_array)\n        img_arr = scaled_df_to_array.reshape(8, 8, len(features))\n        image_list.append(img_arr)\n#         original = Image.fromarray(img_arr)\n#         original.save(\"./Image_directory/{}/deppts_{}_image.png\".format(well_name, i))\n        desc_lst.append(np.around(np.array(lst),decimals=2).reshape(len(lst),))\n        \n    feature_df[\"desc\"]=desc_lst\n    np.save(\"./Well_desc/\"+well_name+\".npy\",np.array(desc_lst))\n    np.save(\"./WellImages_array_directory/\" + well_name + \"_images\" + \".npy\",np.array(image_list))\n    \n#     for imdir in sorted(os.listdir(\"./Image_directory\")):\n#         image_list = []\n#         for filename in sorted(os.listdir(\"./Image_directory/\"+ imdir), key=lambda x:int(re.findall(\"[0-9]+\", x)[0])):\n#             image = cv2.imread(\"./Image_directory/\"+ imdir + \"/\" + filename)\n#             image_list.append(image)\n#         np.save(\"./WellImages_array_directory/\" + imdir + \"_images\" + \".npy\",np.array(image_list))\n    \n    org_df = df.copy()\n    \n    fig, ax = plt.subplots(figsize=(6,48))\n    for i in range(len(features)):\n        plt.plot(df[features[i]+\"_scaled\"],df[\"DEPTH\"])\n        ax.text((i*100)+25,min(df[\"DEPTH\"])-10,features[i],size=10)\n\n    for i in depth_change_points_array:\n        plt.axhline(y=i, color='black', linestyle='-')\n\n\n    plt.gca().invert_yaxis()\n    plt.title(well_name)\n    plt.show()\n    fig.savefig('./Well_markers_pics/{}_markers.png'.format(well_name))\n    feature_df.to_csv(\"./Features_directory/{}_features.csv\".format(well_name), index=False)\n    org_df.to_csv(\"./Org_DataFrame/{}_dataframe.csv\".format(well_name), index=False)\n\n    return org_df, feature_df, dept_org, np.array(lst)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:45:32.744928Z","iopub.execute_input":"2022-07-20T17:45:32.746012Z","iopub.status.idle":"2022-07-20T17:45:32.781729Z","shell.execute_reply.started":"2022-07-20T17:45:32.745874Z","shell.execute_reply":"2022-07-20T17:45:32.780837Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data_dir=\"../input/ovl-las-with-labels/\"\nfiles = os.listdir(data_dir)\nprint(files)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:45:32.783050Z","iopub.execute_input":"2022-07-20T17:45:32.787555Z","iopub.status.idle":"2022-07-20T17:45:32.799173Z","shell.execute_reply.started":"2022-07-20T17:45:32.787497Z","shell.execute_reply":"2022-07-20T17:45:32.798223Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def features(files):\n    well_features = []\n    for i in range(len(files)):\n        features = []\n        las = lasio.read(\"../input/ovl-las-with-labels/\"+files[i])\n        for curve in las.sections['Curves']:\n            features.append(curve.mnemonic)\n        well_features.append(features)\n    \n    common_features = list(set.intersection(*[set(sublist) for sublist in well_features]))\n    return common_features\n        \ncommon_features = features(files)\nprint(common_features)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:45:32.800454Z","iopub.execute_input":"2022-07-20T17:45:32.800805Z","iopub.status.idle":"2022-07-20T17:45:35.963251Z","shell.execute_reply.started":"2022-07-20T17:45:32.800774Z","shell.execute_reply":"2022-07-20T17:45:35.962233Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"final_files_lst=[]\nno_of_features = int(input('Enter the number of features:- '))\n\nfeatures_ = []\ncommon_features = features(files)\nj = 1\nwhile j <= no_of_features:\n    fea = input('Enter the name of the feature:- ')\n    if fea not in common_features:\n        j -= 1\n    else:\n        features_.append(fea)\n    j += 1\n        \nfor i in range(len(files)):\n    org_df,new_df,dept,desc=detect_and_compute(\"../input/ovl-las-with-labels/\"+files[i], features_)\n    final_files_lst.append(files[i])\n#     except:\n#         print(\"missing features in \",files[i])\n        \nfinal_files_lst","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:45:35.964784Z","iopub.execute_input":"2022-07-20T17:45:35.965271Z","iopub.status.idle":"2022-07-20T17:46:48.967110Z","shell.execute_reply.started":"2022-07-20T17:45:35.965226Z","shell.execute_reply":"2022-07-20T17:46:48.966047Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data_dir1=\"./Well_desc/\"\nfiles1 = os.listdir(data_dir1)\nprint(files1)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:48.968410Z","iopub.execute_input":"2022-07-20T17:46:48.968848Z","iopub.status.idle":"2022-07-20T17:46:48.974501Z","shell.execute_reply.started":"2022-07-20T17:46:48.968813Z","shell.execute_reply":"2022-07-20T17:46:48.973440Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# wellno1 = input('Enter the well number1:- ')\n# wellno2 = input('Enter the well number1:- ')\n# df1=pd.read_csv(\"./Features_directory/SES-\" + wellno1 + \"_features.csv\")\n# des1=np.load(\"./Well_desc/SES-\" + wellno1 + \".npy\")\n\n# df2=pd.read_csv(\"./Features_directory/SES-\" + wellno2 + \"_features.csv\")\n# des2=np.load(\"./Well_desc/SES-\" + wellno2 + \".npy\")","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:48.978321Z","iopub.execute_input":"2022-07-20T17:46:48.979075Z","iopub.status.idle":"2022-07-20T17:46:48.986281Z","shell.execute_reply.started":"2022-07-20T17:46:48.979028Z","shell.execute_reply":"2022-07-20T17:46:48.985336Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.neighbors import NearestNeighbors\n\ndef output(wellno1, wellno2, method, well1_feature, well2_feature):\n    \n    wellno1 = wellno1\n    wellno2 = wellno2\n    df1=pd.read_csv(\"./Features_directory/SES-\" + wellno1 + \"_features.csv\")\n    des1=np.load(\"./Well_desc/SES-\" + wellno1 + \".npy\")\n\n    df2=pd.read_csv(\"./Features_directory/SES-\" + wellno2 + \"_features.csv\")\n    des2=np.load(\"./Well_desc/SES-\" + wellno2 + \".npy\")\n\n    nbrs = NearestNeighbors()\n\n    offset= int(input('Enter the offset value:- '))\n\n    df1_dep_lst=[]\n    df2_dep_lst=[]\n    dist_lst=[]\n\n    for i in range(len(df1)):\n        temp=df2[df2[\"DEPTH\"]>(df1[\"DEPTH\"][i]-offset)]\n        temp=temp[temp[\"DEPTH\"]<(df1[\"DEPTH\"][i]+offset)]\n        #print(temp)\n        try:\n            temp_min_dp=min((temp.index).to_list())\n            temp_max_dp=max((temp.index).to_list())\n\n#             if method == \"Spatial KDTree Distance\":\n#                 temp_des=well2_feature[temp_min_dp:temp_max_dp+1]\n#                 dist,idx = spatial.KDTree(temp_des).query(well1_feature[i])\n\n\n#             elif method == \"Cosine Similarity Score\":\n#                 temp = well2_feature[temp_min_dp:temp_max_dp+1]\n#                 distance = cosine_similarity(well1_feature[i].reshape(1, 512), temp)\n#                 lst = distance.tolist()[0]\n#                 dist = max(lst)\n#                 idx = lst.index(dist)\n\n#             else:\n            temp=well2_feature[temp_min_dp:temp_max_dp+1]\n            nbrs.fit(temp)\n            distance, index = nbrs.kneighbors(well1_feature[i].reshape(1, filters*8))\n            lst = distance.tolist()[0]\n            lst_ = index.tolist()[0]\n            dist = lst[0]\n            idx = lst_[0]\n\n            df1_dep_lst.append(df1[\"DEPTH\"][i])\n            df2_dep_lst.append(df2[\"DEPTH\"][idx+temp_min_dp])\n            dist_lst.append(dist)\n            \n#             lst = distance.tolist()[0]\n#             lst_ = index.tolist()[0]\n#             dist = min(lst)\n#             idx = lst.index(dist)\n#             idx_lst.append(lst_[idx])\n#             dept_org.append(df[\"DEPTH\"][lst_[idx]])\n        except:\n            continue\n\n    output_df=pd.DataFrame()\n    output_df[\"ses-\" + wellno1 + \" depth\"]=df1_dep_lst\n    output_df[\"ses-\" + wellno2 + \" depth\"]=df2_dep_lst\n    output_df[\"distance in desc\"]=dist_lst\n    #print(output_df)\n\n    val_con = pd.DataFrame()\n    val_con = output_df[\"ses-\" + wellno2 + \" depth\"].value_counts().to_frame()\n    val_con[\"count\"] = list(val_con[\"ses-\" + wellno2 + \" depth\"])\n    val_con[\"ses-\" + wellno2 + \" depth\"] = list(val_con.index)\n    val_con.index = range(len(val_con))\n    \n    final_output=pd.DataFrame()\n    for i in range(len(val_con)):\n        temp=output_df[output_df[\"ses-\" + wellno2 + \" depth\"]==val_con[\"ses-\" + wellno2 + \" depth\"][i]]\n        final_output=final_output.append(temp[temp[\"distance in desc\"]==min(temp[\"distance in desc\"])])\n\n    #print(final_output)\n    final_output=final_output.sort_values([\"ses-\" + wellno1 + \" depth\"])\n    final_output=final_output.reset_index(drop=True)\n\n    lst=[]\n    for i in range(len(final_output)):\n        lst.append(\"H_{}\".format(i))   \n    final_output[\"Horizon\"]=lst\n    final_output.to_csv(wellno1 + \"_\" + wellno2 + \"_\" + method + \"_\" + \"final_output.csv\", index=False)\n    \n    temp1=pd.DataFrame()\n    temp1[\"Depth\"]=final_output[\"ses-\" + wellno1 + \" depth\"]\n    temp1[\"pick\"]=final_output[\"Horizon\"]\n    temp1[\"Well name\"]=\"ses-\" + wellno1\n\n    temp2=pd.DataFrame()\n    temp2[\"Depth\"]=final_output[\"ses-\" + wellno2 + \" depth\"]\n    temp2[\"pick\"]=final_output[\"Horizon\"]\n    temp2[\"Well name\"]=\"ses-\" + wellno2\n\n    structured_output=temp1.append(temp2)\n    structured_output=structured_output.reset_index(drop=True)\n    structured_output.to_csv(wellno1 + \"_\" + wellno2 + \"_\" + method + \"_\" + \"structured_output.csv\", index=False)\n    \n#     # calculating max and min depth range\n#     minimum = []\n#     maximum = []\n#     for filename in os.listdir(\"./Org_DataFrame\"):\n#         if filename in [\"SES-\" + wellno1 + \"_dataframe.csv\", \"SES-\" + wellno2 + \"_dataframe.csv\"]:\n#             org_df = pd.read_csv(\"./Org_DataFrame/\" + filename)\n#             min_depth = org_df['DEPTH'].min()\n#             max_depth = org_df['DEPTH'].max()\n#             minimum.append(min_depth)\n#             maximum.append(max_depth)\n#         else:\n#             pass\n\n#     min_depth_val = min(minimum)\n#     max_depth_val = max(maximum)\n    \n#     org_df_well1 = pd.read_csv(\"./Org_DataFrame/SES-\" + wellno1 + \"_dataframe.csv\")\n#     org_df_well2 = pd.read_csv(\"./Org_DataFrame/SES-\" + wellno2 + \"_dataframe.csv\")\n    \n#     fig = plt.figure(1, figsize=(15,48))\n\n#     ax1 = fig.add_subplot(121)\n#     ax2 = fig.add_subplot(122)\n\n#     features = ['GR', 'DTC', 'RHOB']\n#     depth_change_points_array = list(structured_output[structured_output[\"Well name\"] == \"ses-\" + wellno1][\"Depth\"])\n\n#     for i in range(len(features)):\n#         ax1.plot(org_df_well1[features[i]+\"_scaled\"],org_df_well1[\"DEPTH\"])\n#         ax1.text((i*100)+25,min(org_df_well1[\"DEPTH\"])-10,features[i],size=10)\n\n#     for i in depth_change_points_array:\n#         ax1.axhline(y=i, color='black', linestyle='-')\n\n#     ax1.invert_yaxis()\n#     ax1.set(title=\"Well SES-\" + wellno1)\n#     ax1.set_ylim(max_depth_val,min_depth_val)\n#     #ax1.set_ylim(max_depth_val,3850)\n\n#     ax1.set_yticks(np.arange(min_depth_val,max_depth_val,50))\n#     #ax1.set_yticks(np.arange(3850,max_depth_val,50))\n\n#     features = ['GR', 'DTC', 'RHOB']\n#     depth_change_points_array = list(structured_output[structured_output['Well name'] == \"ses-\" + wellno2]['Depth'])\n\n#     for i in range(len(features)):\n#         ax2.plot(org_df_well2[features[i]+\"_scaled\"],org_df_well2[\"DEPTH\"])\n#         ax2.text((i*100)+25,min(org_df_well2[\"DEPTH\"])-10,features[i],size=10)\n\n#     for i in depth_change_points_array:\n#         ax2.axhline(y=i, color='black', linestyle='-')\n\n\n#     ax2.invert_yaxis()\n#     ax2.set(title=\"Well SES-\" + wellno2)\n#     ax2.set_ylim(max_depth_val,min_depth_val)\n#     #ax2.set_ylim(max_depth_val,3850)\n\n\n#     plt.setp(ax2.get_yticklabels(), visible = False)\n#     plt.subplots_adjust(wspace = 0)\n\n#     plt.show()\n    \n    return output_df, val_con, final_output, structured_output\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:48.987695Z","iopub.execute_input":"2022-07-20T17:46:48.988200Z","iopub.status.idle":"2022-07-20T17:46:49.016515Z","shell.execute_reply.started":"2022-07-20T17:46:48.988168Z","shell.execute_reply":"2022-07-20T17:46:49.015516Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Wells Images Array and Display Images","metadata":{}},{"cell_type":"code","source":"# img_arr_well1 = np.load(\"./WellImages_array_directory/SES-\" + wellno1 + \"_images.npy\")\n# print(img_arr_well1)\n\n# img_arr_well2 = np.load(\"./WellImages_array_directory/SES-\" + wellno2 + \"_images.npy\")\n# print(img_arr_well2)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:49.017803Z","iopub.execute_input":"2022-07-20T17:46:49.018328Z","iopub.status.idle":"2022-07-20T17:46:49.034994Z","shell.execute_reply.started":"2022-07-20T17:46:49.018289Z","shell.execute_reply":"2022-07-20T17:46:49.034000Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# data_dir=\"./Image_directory/SES-\" + wellno1\n# files = os.listdir(data_dir)\n\n# for i in range(len(files)):\n#     image = cv2.imread(\"./Image_directory/SES-\" + wellno1 + \"/\" + files[i])\n#     #print(image.shape)\n#     plt.imshow(image)\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:49.036554Z","iopub.execute_input":"2022-07-20T17:46:49.036902Z","iopub.status.idle":"2022-07-20T17:46:49.046407Z","shell.execute_reply.started":"2022-07-20T17:46:49.036867Z","shell.execute_reply":"2022-07-20T17:46:49.045620Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# data_dir=\"./Image_directory/SES-\" + wellno2\n# files = os.listdir(data_dir)\n\n# for i in range(len(files)):\n#     image = cv2.imread(\"./Image_directory/SES-\" + wellno2 + \"/\" + files[i])\n#     #print(image.shape)\n#     plt.imshow(image)\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:49.047618Z","iopub.execute_input":"2022-07-20T17:46:49.047990Z","iopub.status.idle":"2022-07-20T17:46:49.057894Z","shell.execute_reply.started":"2022-07-20T17:46:49.047944Z","shell.execute_reply":"2022-07-20T17:46:49.057047Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Descriptor_Features","metadata":{}},{"cell_type":"code","source":"# des1","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:49.059138Z","iopub.execute_input":"2022-07-20T17:46:49.059675Z","iopub.status.idle":"2022-07-20T17:46:49.068158Z","shell.execute_reply.started":"2022-07-20T17:46:49.059642Z","shell.execute_reply":"2022-07-20T17:46:49.067307Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# des2","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:49.069381Z","iopub.execute_input":"2022-07-20T17:46:49.070441Z","iopub.status.idle":"2022-07-20T17:46:49.082292Z","shell.execute_reply.started":"2022-07-20T17:46:49.070391Z","shell.execute_reply":"2022-07-20T17:46:49.081163Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## VGG_Features","metadata":{}},{"cell_type":"code","source":"# from keras.applications.resnet import ResNet50\n# from keras.preprocessing import image\n# from keras.applications.resnet import preprocess_input\n# import numpy as np\n# from PIL import Image as pil_image\n# from keras.applications.vgg16 import VGG16\n# from keras.applications.vgg16 import preprocess_input\n\n\n# model = VGG16(weights='imagenet', include_top=False, input_shape=(32,32,3))\n# for layer in model.layers:\n#     layer.trainable=False\n# print(model.summary())\n\n# for direc in sorted(os.listdir(\"./Image_directory\")):\n#     i = 0\n#     for img_path in sorted(os.listdir(\"./Image_directory/\"+ direc), key=lambda x:int(re.findall(\"[0-9]+\", x)[0])):\n#         image_no = len(os.listdir(\"./Image_directory/\"+ direc))\n#         img = image.load_img(\"./Image_directory/\"+ direc + \"/\" + img_path, target_size=(32, 32))\n#         x = image.img_to_array(img)\n#         x = np.expand_dims(x, axis=0)\n#         x = preprocess_input(x)\n#         #predict image features\n#         images_features = model.predict(x)\n#         vector = images_features[0]\n#         feature = np.empty(shape=(image_no,512))\n#         feature[i] = vector\n#         i += 1\n#     feature = np.round(feature,2)\n#     np.save(\"./WellImages_VGGFeatureVector_directory/\" + direc + \"_VGG_feature_vector\" + \".npy\",np.array(feature))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:49.083799Z","iopub.execute_input":"2022-07-20T17:46:49.084302Z","iopub.status.idle":"2022-07-20T17:46:49.094092Z","shell.execute_reply.started":"2022-07-20T17:46:49.084256Z","shell.execute_reply":"2022-07-20T17:46:49.093204Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# VGG_feavec_well1 = np.load(\"./WellImages_VGGFeatureVector_directory/SES-\" + wellno1 + \"_VGG_feature_vector.npy\")\n# print(VGG_feavec_well1)\n# print('\\r')\n# VGG_feavec_well2 = np.load(\"./WellImages_VGGFeatureVector_directory/SES-\" + wellno2 + \"_VGG_feature_vector.npy\")\n# print(VGG_feavec_well2)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:49.095387Z","iopub.execute_input":"2022-07-20T17:46:49.096115Z","iopub.status.idle":"2022-07-20T17:46:49.110549Z","shell.execute_reply.started":"2022-07-20T17:46:49.096079Z","shell.execute_reply":"2022-07-20T17:46:49.109690Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Entropy_Gaussian_Sobel_Features","metadata":{}},{"cell_type":"code","source":"# import cv2\n# import pandas as pd\n# from skimage.filters.rank import entropy\n# from skimage.morphology import disk\n# from scipy import ndimage as nd\n# from skimage.filters import sobel\n\n# #files = sorted(os.listdir(\"./Image_directory/\"+ \"SES-\" + wellno1), key=lambda x:int(re.findall(\"[0-9]+\", x)[0]))\n\n\n# for imdir in sorted(os.listdir(\"./Image_directory\")):\n#     lst = []\n#     for filename in sorted(os.listdir(\"./Image_directory/\"+ imdir), key=lambda x:int(re.findall(\"[0-9]+\", x)[0])):\n#         img = cv2.imread(\"./Image_directory/\"+ imdir + \"/\" + filename)\n\n#         df = pd.DataFrame()\n\n#         img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n#         img2 = img.reshape(-1)\n#         df['Original Image'] = img2\n\n#         entropy_img = entropy(img, disk(1))\n#         entropy1 = entropy_img.reshape(-1)\n#         df['Entropy'] = entropy1\n\n#         gaussian_img = nd.gaussian_filter(img, sigma=3)\n#         gaussian_img1 = gaussian_img.reshape(-1)\n#         df['Gaussian s3'] = gaussian_img1\n\n#         sobel_img = sobel(img)\n#         sobel1 = sobel_img.reshape(-1)\n#         df['Sobel'] = sobel1\n\n#         x = list(df['Entropy']) + list(df['Gaussian s3']) + list(df['Sobel'])\n#         lst.append(x)\n#     np.save(\"./WellImages_EGSFeatureVector_directory/\" + imdir + \"_EGS_feature_vector\" + \".npy\",np.array(lst))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:49.111872Z","iopub.execute_input":"2022-07-20T17:46:49.113112Z","iopub.status.idle":"2022-07-20T17:46:49.123191Z","shell.execute_reply.started":"2022-07-20T17:46:49.113074Z","shell.execute_reply":"2022-07-20T17:46:49.122009Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# EGS_feavec_well1 = np.load(\"./WellImages_EGSFeatureVector_directory/SES-\" + wellno1 + \"_EGS_feature_vector.npy\")\n# print(EGS_feavec_well1)\n# print('\\r')\n# EGS_feavec_well2 = np.load(\"./WellImages_EGSFeatureVector_directory/SES-\" + wellno2 + \"_EGS_feature_vector.npy\")\n# print(EGS_feavec_well2)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:49.124441Z","iopub.execute_input":"2022-07-20T17:46:49.124785Z","iopub.status.idle":"2022-07-20T17:46:49.140372Z","shell.execute_reply.started":"2022-07-20T17:46:49.124755Z","shell.execute_reply":"2022-07-20T17:46:49.139157Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## AutoEncoder_Features","metadata":{}},{"cell_type":"code","source":"X_1 = np.load('./WellImages_array_directory/SES-168_images.npy')\nX_2 = np.load('./WellImages_array_directory/SES-178_images.npy')\nX_3 = np.load('./WellImages_array_directory/SES-181_images.npy')\nX_4 = np.load('./WellImages_array_directory/SES-182_images.npy')\nX_5 = np.load('./WellImages_array_directory/SES-184_images.npy')\nX_6 = np.load('./WellImages_array_directory/SES-189_images.npy')\nX_7 = np.load('./WellImages_array_directory/SES-191_images.npy')\nX_8 = np.load('./WellImages_array_directory/SES-192_images.npy')\nX_9 = np.load('./WellImages_array_directory/SES-193_images.npy')\n\nx = np.concatenate([X_1, X_2, X_3, X_4, X_5, X_6, X_7, X_8, X_9], axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:49.141544Z","iopub.execute_input":"2022-07-20T17:46:49.142249Z","iopub.status.idle":"2022-07-20T17:46:49.156800Z","shell.execute_reply.started":"2022-07-20T17:46:49.142215Z","shell.execute_reply":"2022-07-20T17:46:49.156051Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test = train_test_split(x, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:49.158181Z","iopub.execute_input":"2022-07-20T17:46:49.158651Z","iopub.status.idle":"2022-07-20T17:46:49.168874Z","shell.execute_reply.started":"2022-07-20T17:46:49.158616Z","shell.execute_reply":"2022-07-20T17:46:49.168047Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import tensorflow\n\nfrom keras.layers import Dense, Flatten, Reshape, Input, InputLayer\nfrom keras.models import Sequential, Model\n\ndef build_autoencoder(img_shape, filters):\n    # The encoder\n    encoder_input = tensorflow.keras.layers.Input(shape=img_shape, name=\"encoder_input\")\n\n    encoder_conv_layer1 = tensorflow.keras.layers.Conv2D(filters=filters, kernel_size=(3, 3), padding=\"same\", strides=1, activation='leaky_relu', name=\"encoder_conv_1\")(encoder_input)\n    # Pooling Layer #1\n    #pool1 = tensorflow.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, name='pool1')(encoder_conv_layer1)\n    #encoder_norm_layer1 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_1\")(encoder_conv_layer1)\n    #encoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(encoder_conv_layer1)\n\n    encoder_conv_layer2 = tensorflow.keras.layers.Conv2D(filters=filters*2, kernel_size=(3,3), padding=\"same\", strides=2, activation='leaky_relu', name=\"encoder_conv_2\")(encoder_conv_layer1)\n    #encoder_norm_layer2 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_2\")(encoder_conv_layer2)\n    #encoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_activ_layer_2\")(encoder_conv_layer2)\n\n    encoder_conv_layer3 = tensorflow.keras.layers.Conv2D(filters=filters*4, kernel_size=(3,3), padding=\"same\", strides=2, activation='leaky_relu', name=\"encoder_conv_3\")(encoder_conv_layer2)\n    #encoder_norm_layer3 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_3\")(encoder_conv_layer3)\n    #encoder_activ_layer3 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_activ_layer_3\")(encoder_conv_layer3)\n\n    encoder_conv_layer4 = tensorflow.keras.layers.Conv2D(filters=filters*8, kernel_size=(3,3), padding=\"same\", strides=2, activation='leaky_relu', name=\"encoder_conv_4\")(encoder_conv_layer3)\n    #encoder_norm_layer4 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_4\")(encoder_conv_layer4)\n    #encoder_activ_layer4 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_activ_layer_4\")(encoder_conv_layer4)\n\n    encoder = tensorflow.keras.models.Model(encoder_input, encoder_conv_layer4, name=\"encoder_model\")\n\n    # The decoder\n    decoder_input = tensorflow.keras.layers.Input(shape=(1, 1, filters*8), name=\"decoder_input\")\n\n    decoder_conv_tran_layer1 = tensorflow.keras.layers.Conv2DTranspose(filters=filters*4, kernel_size=(3, 3), padding=\"same\", strides=2, activation='leaky_relu', name=\"decoder_conv_tran_1\")(decoder_input)\n    #decoder_norm_layer1 = tensorflow.keras.layers.BatchNormalization(name=\"decoder_norm_1\")(decoder_conv_tran_layer1)\n    #decoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_1\")(decoder_conv_tran_layer1)\n\n    decoder_conv_tran_layer2 = tensorflow.keras.layers.Conv2DTranspose(filters=filters*2, kernel_size=(3, 3), padding=\"same\", strides=2, activation='leaky_relu', name=\"decoder_conv_tran_2\")(decoder_conv_tran_layer1)\n    #decoder_norm_layer2 = tensorflow.keras.layers.BatchNormalization(name=\"decoder_norm_2\")(decoder_conv_tran_layer2)\n    #decoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_2\")(decoder_conv_tran_layer2)\n\n    decoder_conv_tran_layer3 = tensorflow.keras.layers.Conv2DTranspose(filters=filters, kernel_size=(3, 3), padding=\"same\", strides=2, activation='leaky_relu', name=\"decoder_conv_tran_3\")(decoder_conv_tran_layer2)\n    #decoder_norm_layer3 = tensorflow.keras.layers.BatchNormalization(name=\"decoder_norm_3\")(decoder_conv_tran_layer3)\n    #decoder_activ_layer3 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_3\")(decoder_conv_tran_layer3)\n\n    decoder_conv_tran_layer4 = tensorflow.keras.layers.Conv2DTranspose(filters=no_of_features, kernel_size=(3, 3), padding=\"same\", strides=1, activation='leaky_relu', name=\"decoder_conv_tran_4\")(decoder_conv_tran_layer3)\n    #decoder_norm_layer4 = tensorflow.keras.layers.BatchNormalization(name=\"decoder_norm_4\")(decoder_conv_tran_layer4)\n    #decoder_activ_layer4 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_4\")(decoder_conv_tran_layer4)\n\n#     decoder_conv_tran_layer5 = tensorflow.keras.layers.Conv2DTranspose(filters=3, kernel_size=(3, 3), padding=\"same\", strides=1, activation='leaky_relu', name=\"decoder_conv_tran_5\")(decoder_conv_tran_layer4)\n#     #decoder_norm_layer5 = tensorflow.keras.layers.BatchNormalization(name=\"decoder_norm_5\")(decoder_conv_tran_layer5)\n#     decoder_activ_layer5 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_5\")(decoder_conv_tran_layer5)\n\n    decoder = tensorflow.keras.models.Model(decoder_input, decoder_conv_tran_layer4, name=\"decoder_model\")\n    \n    return encoder, decoder","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:49.170792Z","iopub.execute_input":"2022-07-20T17:46:49.171275Z","iopub.status.idle":"2022-07-20T17:46:55.982042Z","shell.execute_reply.started":"2022-07-20T17:46:49.171223Z","shell.execute_reply":"2022-07-20T17:46:55.980908Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#filters= int(input('Enter the value of filter:- '))\nfilters= 128\n\nIMG_SHAPE = (8, 8, no_of_features)\nencoder, decoder = build_autoencoder(IMG_SHAPE, filters)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:55.983644Z","iopub.execute_input":"2022-07-20T17:46:55.984572Z","iopub.status.idle":"2022-07-20T17:46:56.855843Z","shell.execute_reply.started":"2022-07-20T17:46:55.984523Z","shell.execute_reply":"2022-07-20T17:46:56.854755Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"encoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:56.857627Z","iopub.execute_input":"2022-07-20T17:46:56.858112Z","iopub.status.idle":"2022-07-20T17:46:56.866184Z","shell.execute_reply.started":"2022-07-20T17:46:56.858067Z","shell.execute_reply":"2022-07-20T17:46:56.864952Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"decoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:56.867668Z","iopub.execute_input":"2022-07-20T17:46:56.868944Z","iopub.status.idle":"2022-07-20T17:46:56.889374Z","shell.execute_reply.started":"2022-07-20T17:46:56.868891Z","shell.execute_reply":"2022-07-20T17:46:56.888041Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"inp = Input(IMG_SHAPE)\ncode = encoder(inp)\nreconstruction = decoder(code)\n\nautoencoder = Model(inp,reconstruction)\nautoencoder.compile(optimizer='adamax', loss='mse', metrics=['accuracy'])\n\nhistory = autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, shuffle=True, validation_data=(X_test, X_test))","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:46:56.890947Z","iopub.execute_input":"2022-07-20T17:46:56.891866Z","iopub.status.idle":"2022-07-20T17:53:17.482084Z","shell.execute_reply.started":"2022-07-20T17:46:56.891817Z","shell.execute_reply":"2022-07-20T17:53:17.481085Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"autoencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:53:17.486408Z","iopub.execute_input":"2022-07-20T17:53:17.486780Z","iopub.status.idle":"2022-07-20T17:53:17.494054Z","shell.execute_reply.started":"2022-07-20T17:53:17.486749Z","shell.execute_reply":"2022-07-20T17:53:17.493064Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:53:17.495829Z","iopub.execute_input":"2022-07-20T17:53:17.496603Z","iopub.status.idle":"2022-07-20T17:53:17.711653Z","shell.execute_reply.started":"2022-07-20T17:53:17.496555Z","shell.execute_reply":"2022-07-20T17:53:17.710672Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"encoded_data = encoder.predict(X_test)\ndecoded_data = decoder.predict(encoded_data)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:53:17.713441Z","iopub.execute_input":"2022-07-20T17:53:17.714206Z","iopub.status.idle":"2022-07-20T17:53:18.191181Z","shell.execute_reply.started":"2022-07-20T17:53:17.714158Z","shell.execute_reply":"2022-07-20T17:53:18.190087Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# wellno1 = \"182\"\n# wellno2 = \"168\"\n\n# img_arr_well1 = np.load(\"./WellImages_array_directory/SES-\" + wellno1 + \"_images.npy\")\n# encoded_data = encoder.predict(img_arr_well1)\n\n# Autoencoder_feavec_well1 = encoded_data.reshape(encoded_data.shape[0], 512)\n# print(Autoencoder_feavec_well1)\n\n# img_arr_well2 = np.load(\"./WellImages_array_directory/SES-\" + wellno2 + \"_images.npy\")\n# encoded_data = encoder.predict(img_arr_well2)\n\n# Autoencoder_feavec_well2 = encoded_data.reshape(encoded_data.shape[0], 512)\n# print(Autoencoder_feavec_well2)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:53:18.192517Z","iopub.execute_input":"2022-07-20T17:53:18.192857Z","iopub.status.idle":"2022-07-20T17:53:18.197784Z","shell.execute_reply.started":"2022-07-20T17:53:18.192828Z","shell.execute_reply":"2022-07-20T17:53:18.196356Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# from sklearn.preprocessing import MinMaxScaler\n\n# scaler = MinMaxScaler()\n# model1=scaler.fit(Autoencoder_feavec_well1)\n# Autoencoder_feavec_well1=model1.transform(Autoencoder_feavec_well1)\n\n# model2=scaler.fit(Autoencoder_feavec_well2)\n# Autoencoder_feavec_well2=model2.transform(Autoencoder_feavec_well2)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:53:18.199618Z","iopub.execute_input":"2022-07-20T17:53:18.200416Z","iopub.status.idle":"2022-07-20T17:53:18.212121Z","shell.execute_reply.started":"2022-07-20T17:53:18.200367Z","shell.execute_reply":"2022-07-20T17:53:18.211225Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# **Result**","metadata":{}},{"cell_type":"code","source":"First_pair = [\"181\", \"189\", \"193\", \"178\", \"191\", \"184\", \"168\", \"192\"]\nSecond_pair = [\"189\", \"193\", \"178\", \"191\", \"184\", \"168\", \"192\", \"182\"]\n\nwell_pairs = zip(First_pair, Second_pair)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:53:18.213918Z","iopub.execute_input":"2022-07-20T17:53:18.214789Z","iopub.status.idle":"2022-07-20T17:53:18.225552Z","shell.execute_reply.started":"2022-07-20T17:53:18.214737Z","shell.execute_reply":"2022-07-20T17:53:18.224516Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nDescriptor_Features and EGS_Features can not work with Cosine Similarity Score and Nearest Neighbours\nbecause need reshaping from 192 to 512\n\"\"\"\n\n\"\"\"\nVGG_Features giving error because Feature Input contains NaN, infinity or a value too large for dtype('float64')\nexcept in case of Spatial KDTree Distance Method but repeating ses-192 depth values because of same distance\n\"\"\"\n\n# Spatial KDTree Distance\n# output_df, val_con, final_output, structured_output = output(\"168\", \"192\", \"Spatial KDTree Distance\", des1, des2)\n# output_df, val_con, final_output, structured_output = output(\"168\", \"192\", \"Spatial KDTree Distance\", VGG_feavec_well1, VGG_feavec_well2)\n# output_df, val_con, final_output, structured_output = output(\"168\", \"192\", \"Spatial KDTree Distance\", EGS_feavec_well1, EGS_feavec_well2)\n# output_df, val_con, final_output, structured_output = output(\"168\", \"192\", \"Spatial KDTree Distance\", Autoencoder_feavec_well1, Autoencoder_feavec_well2)\n\n\n# Cosine Similarity Score\n# output_df, val_con, final_output, structured_output = output(\"168\", \"192\", \"Cosine Similarity Score\", Autoencoder_feavec_well1, Autoencoder_feavec_well2)\n\n\n# Nearest Neighbours\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nfor wellno1, wellno2 in well_pairs:\n    # print(\"{}-{}\".format(wellno1, wellno2))\n    img_arr_well1 = np.load(\"./WellImages_array_directory/SES-\" + wellno1 + \"_images.npy\")\n    Autoencoder_feavec_well1 = encoder.predict(img_arr_well1).reshape(img_arr_well1.shape[0], filters*8)\n\n    img_arr_well2 = np.load(\"./WellImages_array_directory/SES-\" + wellno2 + \"_images.npy\")\n    Autoencoder_feavec_well2 = encoder.predict(img_arr_well2).reshape(img_arr_well2.shape[0], filters*8)\n     \n    scaler = MinMaxScaler()\n    model1=scaler.fit(Autoencoder_feavec_well1)\n    Autoencoder_feavec_well1=model1.transform(Autoencoder_feavec_well1)\n    #print(Autoencoder_feavec_well1)\n\n    model2=scaler.fit(Autoencoder_feavec_well2)\n    Autoencoder_feavec_well2=model2.transform(Autoencoder_feavec_well2)\n    #print(Autoencoder_feavec_well2)\n\n    output_df, val_con, final_output, structured_output = output(wellno1, wellno2, \"Nearest Neighbours\", Autoencoder_feavec_well1, Autoencoder_feavec_well2)\n    #print(final_output)\n    \n# output_df, val_con, final_output, structured_output = output(wellno1, wellno2, \"Nearest Neighbours\", Autoencoder_feavec_well1, Autoencoder_feavec_well2)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:53:18.227392Z","iopub.execute_input":"2022-07-20T17:53:18.228181Z","iopub.status.idle":"2022-07-20T17:53:51.433819Z","shell.execute_reply.started":"2022-07-20T17:53:18.228137Z","shell.execute_reply":"2022-07-20T17:53:51.432596Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv('./181_189_Nearest Neighbours_final_output.csv')\ndf2 = pd.read_csv('./189_193_Nearest Neighbours_final_output.csv')\ndf3 = pd.read_csv('./193_178_Nearest Neighbours_final_output.csv')\ndf4 = pd.read_csv('./178_191_Nearest Neighbours_final_output.csv')\ndf5 = pd.read_csv('./191_184_Nearest Neighbours_final_output.csv')\ndf6 = pd.read_csv('./184_168_Nearest Neighbours_final_output.csv')\ndf7 = pd.read_csv('./168_192_Nearest Neighbours_final_output.csv')\ndf8 = pd.read_csv('./192_182_Nearest Neighbours_final_output.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:53:51.435560Z","iopub.execute_input":"2022-07-20T17:53:51.436231Z","iopub.status.idle":"2022-07-20T17:53:51.468831Z","shell.execute_reply.started":"2022-07-20T17:53:51.436185Z","shell.execute_reply":"2022-07-20T17:53:51.468071Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# def update_df(df1, df2):\n#     common_col = list(df1.columns)[1]\n#     horizon = list(df2['Horizon'])\n#     j = 1\n#     for i in range(len(df2)):\n#         if list(df2[common_col])[i] not in list(df1[common_col]):\n#             horizon[i] = 'H_' + str(int(sorted(list(df1['Horizon']), key=lambda x: int(x[2:]))[-1][2:]) + j)\n#             j += 1\n#         else:\n#             idx = list(df1[common_col]).index(list(df2[common_col])[i])\n#             horizon[i] = df1.loc[idx, 'Horizon']\n\n#     df2['Horizon'] = horizon\n#     return df2","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:53:51.470147Z","iopub.execute_input":"2022-07-20T17:53:51.470508Z","iopub.status.idle":"2022-07-20T17:53:51.475961Z","shell.execute_reply.started":"2022-07-20T17:53:51.470471Z","shell.execute_reply":"2022-07-20T17:53:51.474480Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# df1","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:53:51.477859Z","iopub.execute_input":"2022-07-20T17:53:51.478578Z","iopub.status.idle":"2022-07-20T17:53:51.488576Z","shell.execute_reply.started":"2022-07-20T17:53:51.478542Z","shell.execute_reply":"2022-07-20T17:53:51.487664Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# final_output = update_df(df1, df2)\n# # final_output = update_df(df2, df3)\n# # final_output = update_df(df3, df4)\n# # final_output = update_df(df4, df5)\n# # final_output = update_df(df5, df6)\n# # final_output = update_df(df6, df7)\n# # final_output = update_df(df7, df8)\n\n# temp1=pd.DataFrame()\n# temp1[\"Depth\"]=final_output[list(final_output.columns)[0]]\n# temp1[\"pick\"]=final_output[\"Horizon\"]\n# temp1[\"Well name\"]=list(final_output.columns)[0][:-6]\n\n# temp2=pd.DataFrame()\n# temp2[\"Depth\"]=final_output[list(final_output.columns)[1]]\n# temp2[\"pick\"]=final_output[\"Horizon\"]\n# temp2[\"Well name\"]=list(final_output.columns)[1][:-6]\n\n# structured_output=temp1.append(temp2)\n# structured_output=structured_output.reset_index(drop=True)\n# #structured_output.to_csv(\"168_192_FeatureVector_correlation_output.csv\")\n# structured_output","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:53:51.489614Z","iopub.execute_input":"2022-07-20T17:53:51.490648Z","iopub.status.idle":"2022-07-20T17:53:51.501091Z","shell.execute_reply.started":"2022-07-20T17:53:51.490597Z","shell.execute_reply":"2022-07-20T17:53:51.499781Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def update_df():\n    First_pair = [\"181\", \"189\", \"193\", \"178\", \"191\", \"184\", \"168\", \"192\"]\n    Second_pair = [\"189\", \"193\", \"178\", \"191\", \"184\", \"168\", \"192\", \"182\"]\n\n    well_pairs = list(zip(First_pair, Second_pair))\n    #df = pd.read_csv('./' + well_pairs[0][0] + \"_\" + well_pairs[0][1] + '_Nearest Neighbours_structured_output.csv')\n    #df.to_csv(well_pairs[0][0] + \"_\" + well_pairs[0][1] + \"_updated_structured_output.csv\", index=False)\n    well_df = pd.DataFrame()\n    \n    for i in range(len(well_pairs)):\n        try:\n            df = pd.read_csv('./' + well_pairs[i][0] + \"_\" + well_pairs[i][1] + '_Nearest Neighbours_final_output.csv')\n            #print(df)\n            \n            temp1=pd.DataFrame()\n            temp1[\"Depth\"]=df[list(df.columns)[0]]\n            temp1[\"pick\"]=df[\"Horizon\"]\n            temp1[\"Well name\"]=list(df.columns)[0][:-6]\n\n            temp2=pd.DataFrame()\n            temp2[\"Depth\"]=df[list(df.columns)[1]]\n            temp2[\"pick\"]=df[\"Horizon\"]\n            temp2[\"Well name\"]=list(df.columns)[1][:-6]\n\n            structured_output=temp1.append(temp2)\n            structured_output=structured_output.reset_index(drop=True)\n            well_df = well_df.append(structured_output)\n            \n            df_ = pd.read_csv('./' + well_pairs[i+1][0] + \"_\" + well_pairs[i+1][1] + '_Nearest Neighbours_final_output.csv')\n\n            common_col = list(df.columns)[1]\n            horizon = list(df_['Horizon'])\n            j = 1\n            for k in range(len(df_)):\n                if list(df_[common_col])[k] not in list(df[common_col]):\n                    horizon[k] = 'H_' + str(int(sorted(list(df['Horizon']), key=lambda x: int(x[2:]))[-1][2:]) + j)\n                    j += 1\n                else:\n                    idx = list(df[common_col]).index(list(df_[common_col])[k])\n                    horizon[k] = df.loc[idx, 'Horizon']\n\n            df_['Horizon'] = horizon\n            df_.to_csv(well_pairs[i+1][0] + \"_\" + well_pairs[i+1][1] + '_Nearest Neighbours_final_output.csv', index=False)\n            \n            \n            #structured_output.to_csv(well_pairs[i+1][0] + \"_\" + well_pairs[i+1][1] + \"_updated_structured_output.csv\", index=False)\n        \n        except:\n            pass\n    \n    well_df=well_df.reset_index(drop=True)\n    well_df.drop_duplicates(inplace=True)\n    return well_df\n        \noutput = update_df()\noutput.to_csv('final_output.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:53:51.503065Z","iopub.execute_input":"2022-07-20T17:53:51.503583Z","iopub.status.idle":"2022-07-20T17:53:51.635186Z","shell.execute_reply.started":"2022-07-20T17:53:51.503549Z","shell.execute_reply":"2022-07-20T17:53:51.634029Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"output","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:53:51.636590Z","iopub.execute_input":"2022-07-20T17:53:51.636988Z","iopub.status.idle":"2022-07-20T17:53:51.657507Z","shell.execute_reply.started":"2022-07-20T17:53:51.636943Z","shell.execute_reply":"2022-07-20T17:53:51.656778Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"output['pick'].value_counts()   #.to_frame()#.loc['H_0', 'pick']","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:53:51.658659Z","iopub.execute_input":"2022-07-20T17:53:51.659240Z","iopub.status.idle":"2022-07-20T17:53:51.668300Z","shell.execute_reply.started":"2022-07-20T17:53:51.659201Z","shell.execute_reply":"2022-07-20T17:53:51.667318Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}